# general settings
# name: debug
name: 97_fp16_b63
model_type: BCEModel
manual_seed: 0
cudnn_deterministic: true

# common settings
common:
  bert: &bert hfl/chinese-roberta-wwm-ext
  vit: &vit microsoft/swin-large-patch4-window12-384-in22k
  fp16: &fp16 true

# dataset and data loader settings
datasets:
  train:
    name: train_ClusterDataset
    type: PairDataset
    image_dir: /cache_ccks/item_images
    pair_path: /cache_ccks/pair_train.jsonl
    info_path: /cache_ccks/item_train_info.jsonl
    tokenizer: *bert
    max_len: 140

    # data loader
    batch_size_per_gpu: 4
    num_worker_per_gpu: 4
    pin_memory: true

  val:
    name: val_PairDataset
    type: PairDataset
    image_dir: /cache_ccks/item_images
    pair_path: /cache_ccks/pair_val.jsonl
    info_path: /cache_ccks/item_train_info.jsonl
    tokenizer: *bert
    max_len: 140

    # data loader
    batch_size_per_gpu: 64
    num_worker_per_gpu: 4
    pin_memory: true

  test:
    name: test_PairDataset
    type: PairDataset
    image_dir: /cache_ccks/item_images
    pair_path: /cache_ccks/item_test_pair.jsonl
    info_path: /cache_ccks/item_test_info.jsonl
    tokenizer: *bert
    max_len: 140

    # data loader
    batch_size_per_gpu: 64
    num_worker_per_gpu: 4
    pin_memory: true

# network structures
network:
  type: VLArch
  bert: *bert
  vit: *vit
  fp16: *fp16

# path
path:
  pretrain_network: ~
  strict_load: true

# training settings
train:
  optim:
    type: Adam
    lr: !!float 2e-6
    weight_decay: !!float 1e-6
    betas: [0.9, 0.999]

  scheduler:
    type: CosineAnnealingRestartLR
    periods: [100000]
    restart_weights: [1]
    eta_min: !!float 1e-7

  total_iter: 100000
  grad_clip_norm: 0.5

# logging settings
logger:
  print_freq: 100
  save_checkpoint_freq: 2000
  wandb: ~

find_unused_parameters: false

deepspeed:
  fp16:
    enabled: *fp16

